---
title: "hyperparameter-tuning"
author: Rachel Delorie
format: html
execute:
  echo: true
---
```{r setup/EDA}
library(tidymodels)
library(recipes)
library(yardstick)
library(ggthemes)
library(ggplot2)
library(patchwork)
library(ggfortify)
library(parsnip)
library(tidyverse)
library(visdat)
library(powerjoin)
library(skimr)
library(xgboost)
library(dplyr)
library(purrr)
library(glue)
library(vip)
library(baguette)

# Data Import/Tidy/Transform	
root  <- 'https://gdex.ucar.edu/dataset/camels/file'
download.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', 
              'data/camels_attributes_v2.0.pdf')
types <- c("clim", "geol", "soil", "topo", "vege", "hydro")

# Where the files live online ...
remote_files  <- glue('{root}/camels_{types}.txt')
# where we want to download the data ...

local_files   <- glue('data/camels_{types}.txt')
walk2(remote_files, local_files, download.file, quiet = TRUE)

# Read and merge data
camels <- map(local_files, read_delim, show_col_types = FALSE) 
camels <- power_full_join(camels ,by = 'gauge_id') 

camels <- camels %>% 
  mutate(logQmean = log(q_mean)) %>% 
  mutate(across(everything(), as.double))

skim(camels)
vis_dat(camels)
```

```{r}
set.seed(567)
camels <- camels %>%  
  mutate(logQmean = log(q_mean))

# Generate the split
camels_split <- initial_split(camels, prop = 0.8)
camels_train <- training(camels_split)
camels_test  <- testing(camels_split)

camels_cv <- vfold_cv(camels_train, v = 10)

rec <-  recipe(logQmean ~ aridity + p_mean, data = camels_train) %>%
  # Log transform the predictor variables (aridity and p_mean)
  
  step_log(all_predictors()) %>%
  # Add an interaction term between aridity and p_mean
  step_interact(terms = ~ aridity:p_mean) |> 
  # Drop any rows with missing values in the pred
  step_naomit(all_predictors(), all_outcomes())

# Prepare the data
baked_data <- prep(rec, camels_train) |> 
  bake(new_data = NULL)

# Interaction with lm
#  Base lm sets interaction terms with the * symbol
lm_base <- lm(logQmean ~ aridity * p_mean, data = baked_data)
summary(lm_base)

test_data <-  bake(prep(rec), new_data = camels_test)
test_data$lm_pred <- predict(lm_base, newdata = test_data)

# Extract the model coefficients from the workflow
summary(extract_fit_engine(lm_wf))$coefficients

rf_data <- augment(rf_wf, new_data = camels_test)
dim(rf_data)

# adding an nnet to provided code
nn_model <- bag_mlp() %>% 
  set_engine("nnet") %>% 
  set_mode("regression") 

nn_wf <- workflow() %>% 
  add_recipe(rec) %>% 
  add_model(nn_model) %>% 
  fit(data = camels_train)

# adding an xgboost to provided code
xg_model <- boost_tree() %>% 
  set_engine("xgboost") %>% 
  set_mode("regression") 

xg_wf <- workflow() %>% 
  add_recipe(rec) %>% 
  add_model(xg_model) %>% 
  fit(data = camels_train)

wf <- workflow_set(list(rec), list(lm_model, rf_model, nn_model, xg_model)) %>%
  workflow_map(resamples = camels_cv) 

autoplot(wf)
# Based on the visualized metrics, the best model is bag_mlp (the neural net). I think it worked the best because it is the most capable of modeling complex patterns, as well as scalability and generalization. The engine is nnet and the mode is regression. 
```

```{r Lab 8}
#model tuning
nn_model <- bag_mlp(
  hidden_units = tune(), 
  penalty = tune()
) %>%
  set_engine("nnet") %>%
  set_mode("regression")

wf_tune<- workflow() %>% 
  add_recipe(rec) %>% 
  add_model(nn_model)

dials <- extract_parameter_set_dials(wf_tune)

# define search space
my.grid <- grid_space_filling(dials, size = 20)

model_params <-  tune_grid(
    wf_tune,
    resamples = camels_cv,
    grid = my.grid,
    metrics = metric_set(rmse, rsq, mae),
    control = control_grid(save_pred = TRUE)
  )
autoplot(model_params)
collect_metrics(model_params)
best_mae <- show_best(model_params, metric = "mae", n = 1)
hp_best <- select_best(model_params, metric = "mae")
#> The first row shows the mean MAE across resamples. It also showws the standard error of the MAE estimate, the number of resamples used, and the mean standard error. Penalty is the best hyperparameter set for this model. 

final_wf <- finalize_workflow(wf_tune, hp_best)
final_fit <- last_fit(final_wf, split = camels_split)
last_fit <- last_fit(final_wf, split = camels_split)
final_metrics <- collect_metrics(last_fit)

# the final model's rmse 53.5% and the rsq is 78%. This means that 78% of the variance is explained by the model. This is a decent number. The rmse is the average prediction error, and this percentage is above 50% which is a pretty high error amount. This model is reasonably good, but the rmse suggests plenty of room for improvement. 

predictions <- collect_predictions(model_params)

ggplot(predictions, aes(x = .pred, y = logQmean)) +
  geom_smooth(method = lm, color = "blue") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  scale_color_gradient() +
  labs(
    title = "Actual vs. Predicted Values", 
    x = "Predicted", 
    y = "Actual")

final_fit_full <- fit(final_wf, data = camels)
augmented_preds <- augment(final_fit_full, new_data = camels)

augmented_preds <- augmented_preds %>% 
  mutate(residual_sq = (logQmean - .pred)^2)

map_preds <- ggplot(augmented_preds, aes(x = .pred, y = logQmean)) +
  geom_point(aes(color = .pred), size = 3, alpha = 0.8) +
  scale_color_viridis_c(name = "Predicted") +
  coord_fixed() +
  labs(title = "Map of Predicted logQmean") +
  theme_minimal()

map_resid <- ggplot(augmented_preds, aes(x = .pred, y = residual_sq) +
  geom_point() +
  coord_fixed() +
   scale_color_viridis_c(name = "ResidualÂ²") +
  labs(title = "Map of Squared Residuals") +
  theme_minimal()

library(patchwork
maps_combined <- map_preds + map_resid

maps_combined

```

